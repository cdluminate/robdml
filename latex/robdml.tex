% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage[review]{cvpr}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

\usepackage{microtype}
\usepackage{xcolor}
\newcommand{\oo}[1]{\textcolor{orange}{#1}}
\include{math_commands.tex}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{201} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2022}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Enhancing Adversarial Robustness for Deep Metric Learning}

\author{Mo Zhou ~~~~~~~ Vishal Patel\\
Johns Hopkins University\\
{\tt\small mzhou32@jhu.edu ~~ vpatel36@jhu.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
}
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
	Deep metric learning models, being vulnerable to adversarial
	attacks, have safety and security implications in applications.
	%
	Improving the adversarial robustness of a model against the attacks becomes
	an important problem.
	%
	The existing defense methods are based on adversarial training.
	%
	However, they \oo{(1) robustness (2) speed/cost. (3) sampling matters.}
	%
	In this paper, we \oo{TBD}.
	%
	The proposed method is validated on three commonly
	used deep metric learning datasets, namely CUB-200-2011, Cars-196,
	and Stanford Online Product.
	%
	Comprehensive experimental results show our method outperforms
	the existing defense methods.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:1}

% what is deep metric learning

Given a set of data points, a metric gives a distance value between each pair
of them, while Deep Metric Learning (DML) aims to learn such a metric
leveraging the representational power of deep neural networks.
%
DML has been extensively studied~[], and has a wide range of applications
such as image retrieval~[] and face recognition~[].

% why defense in deep metric learning 

Despite the improvements of this field thanks to the advancement of deep neural
networks, recent research works suggest that DML models are vulnerable to
adversarial attacks, where an imperceptible perturbation could incur unexpected
or covertly manipulated results~\cite{advrank}.
%
Such vulnerability poses safety, security, and fairness concerns in the
applications of DML.
%
For example, impersonation or recognition evation are possible for DML-based
face-identification system~[].
%
To counter the attacks (or reducing the vulnerability), it is important to
design defense methods to improve the adversarial robustness of DML models.

% existing methods & problem
A series of defense methods for DML are proposed~[], inspired by the Madry's
adversarial training method~[], as it is kown as one of the most effective
defense methods for deep neural network classifiers.
%
However, it has been noted that
%
(1) the direct adoptation of Madry's defense will easily lead to model collapse
due to producing very hard sample triplets;
%
(2) \oo{the sota defense lacks ()};
%
and (3) the adversarial training procedure is very time-consuming compared
to the training process of a regular DML model.

% for problem 1
Triplet hardness still matters in adversarial training for deep metric
learning.
%
propose hardness manipulation for.
solution to problem 1

% for problem 2
ACT and amdsemi have distinct characteristics.
solution to problem 2

% for problem 3
update of advtrain acceleration.
solution to problem 3

% evaluation and conclusion
experimetal evaluations

% contributions
In brief, our contribusions include:
%
\begin{enumerate}
	%
	\item Hardness manipulation is proposed for the adversarial training
		of triplet-based deep metric learning models, which avoids model
		collapse in the typical min-max adversarial training setting.
		\oo{We discover that blah}.
		Our proposed method achieves higher adversarial robustness compared
		to the state-of-the-art.
		%
	\item Combine and even better.
		%
	\item Accelerate and reduce the cost for reproducing and applying.
		%
\end{enumerate}

\section{Related Works}
\label{sec:2}

\textbf{Adversarial Attack.}

\textbf{Adversarial Defense.}

\textbf{Deep Metric Learning.}
\cite{advrank,advorder,robrank}

\section{Our Approach}
\label{sec:3}

\section{Experiments}
\label{sec:4}

\subsection{Evaluation Protocol}

\textbf{Dataset.}

\section{Discussions}
\label{sec:5}

1. adversarial training speed.

\section{Conclusion}
\label{sec:6}

\cite{Authors14}

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\input{appendix.tex}

\end{document}
