% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage[review]{cvpr}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

\usepackage{microtype}
\usepackage{xcolor}
\newcommand{\oo}[1]{\textcolor{orange}{#1}}
\include{math_commands.tex}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{201} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2022}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Enhancing Adversarial Robustness for Deep Metric Learning}

\author{Mo Zhou ~~~~~~~ Vishal Patel\\
Johns Hopkins University\\
{\tt\small mzhou32@jhu.edu ~~ vpatel36@jhu.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
}
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
	% background
	Deep metric learning, being vulnerable to adversarial
	attacks, has safety and security implications in its applications.
	% importance
	It is crucial to improve adversarial robustness of deep
	metric learning.
	% insight
	However, as deep metric model with triplet loss is prone to collapse with
	excessively hard samples, the previous methods refrain from using the
	classical min-max adversarial training paradigm, but also suffer from
	inefficiency.
	% our finding
	In this paper, we reveal a significant impact of triplet sampling strategy
	on the adversarial training.
	% solution 1
	Based on this, Hardness Manipulation is proposed to adversarially perturb
	a given triplet into a specified hardness level in min-max adversarial
	training, instead of creating hardest triplets rendering model collapse.
	% solution 2
	To further improve the model performance, we propose a Gradual
	Adversary to dynamicly change the hardness level to balance metric
	learning and adversarial learning.
	% Experiment
	The proposed method is validated on three commonly
	used deep metric learning datasets, namely CUB-200-2011, Cars-196,
	and Stanford Online Product.
	% Conclusion
	Comprehensive experimental results show our method outperforms
	the existing defense methods, while achieving clearly higher
	efficiency at a lower training cost.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:1}

% what is deep metric learning

Given a set of data points, a metric gives a distance value between each pair
of them.
%
Deep Metric Learning (DML) aims to learn such a metric between two inputs (\eg,
images) leveraging the representational power of deep neural networks.
%
DML has been extensively studied~\cite{revisiting}, and has a
wide range of applications such
as image retrieval~\cite{imagesim2} and face recognition~\cite{facenet}.

% why defense in deep metric learning 

Despite the improvements of this field thanks to the advancement of deep neural
networks, recent research works suggest that DML models are vulnerable to
adversarial attacks, where an imperceptible perturbation could incur unexpected
or covertly manipulated results~\cite{advrank,advorder}.
%
Such vulnerability poses safety, security, and fairness concerns in the
applications of DML.
%
For example, impersonation or recognition evation are possible for DML-based
face-identification system.
%
To counter the attacks (or reducing the vulnerability), it is important to
design defense methods to improve the adversarial robustness of DML models.

% existing methods & problem
Several defense methods for DML are proposed in the
literature~\cite{advrank,robrank}, inspired by the Madry's adversarial training
method~\cite{madry}, as it is kown as one of the most effective defense methods
for deep neural network classifiers.
%
However, it has been noted that
%
(1) the robustness level achieved by the existing methods is still insufficient
to counter the attacks;
%
(2) the direct adoptation of Madry's min-max adversarial training~\cite{madry} will easily
lead to model collapse due to producing very hard sample triplets;
%
(3) the adversarial training procedure is very time-consuming compared to
the training process of a regular DML model, but existing defense methods
are incompatible to acceleration methods like Free Adversarial Training~\cite{freeat}.

% for problem 1
Triplet hardness still matters in adversarial training for deep metric
learning.
%
propose hardness manipulation for.
solution to problem 1

% for problem 2
ACT and amdsemi have distinct characteristics.
solution to problem 2

% for problem 3
update of advtrain acceleration.
solution to problem 3

% evaluation and conclusion
experimetal evaluations

% contributions
In brief, our contribusions include:
%
\begin{enumerate}
	%
	\item Hardness manipulation is proposed for the adversarial training
		of triplet-based deep metric learning models, which avoids model
		collapse in the typical min-max adversarial training setting.
		\oo{We discover that blah}.
		Our proposed method achieves higher adversarial robustness compared
		to the state-of-the-art.
		%
	\item Gradual Adversary.
		%
	\item Benchmark existing metric learning loss functions with adversarial
		training for future reference.
\end{enumerate}

\section{Related Works}
\label{sec:2}

\textbf{Adversarial Attack.}

\textbf{Adversarial Defense.}

\textbf{Deep Metric Learning.}
\cite{advrank,advorder,robrank}

\section{Our Approach}
\label{sec:3}

\subsection{Hardness Manipulation}

\subsection{Gradual Adversary}

\section{Experiments}
\label{sec:4}

1. hardness manipulation, comparison with state-of-the-art.

\subsection{Evaluation Protocol}

\textbf{Dataset.}

\section{Discussions}
\label{sec:5}

1. adversarial training speed.

\section{Conclusion}
\label{sec:6}

\cite{Authors14}

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\input{appendix.tex}

\end{document}
