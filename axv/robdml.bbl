\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In {\em Proc. Int. Conf. Mach. Learn.}, pages 274--283, 2018.

\bibitem{currat}
Qi-Zhi Cai, Chang Liu, and Dawn Song.
\newblock Curriculum adversarial training.
\newblock In {\em Int. Joint Conf. Artif. Intell.}, page 3740–3747, 2018.

\bibitem{cw}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em Proc. IEEE Symposium on Security and Privacy}, pages 39--57,
  2017.

\bibitem{apgd}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In {\em Proc. Int. Conf. Mach. Learn.}, pages 2206--2216, 2020.

\bibitem{benchmarking}
Yinpeng Dong, Qi-An Fu, Xiao Yang, Tianyu Pang, Hang Su, Zihao Xiao, and Jun
  Zhu.
\newblock Benchmarking adversarial robustness on image classification.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  321--331, 2020.

\bibitem{domainface}
Masoud Faraki, Xiang Yu, Yi-Hsuan Tsai, Yumin Suh, and Manmohan Chandraker.
\newblock Cross-domain similarity learning for face recognition in unseen
  domains.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  15292--15301, 2021.

\bibitem{advdpqn}
Yan Feng, Bin Chen, Tao Dai, and Shu-Tao Xia.
\newblock Adversarial attack on deep product quantization network for image
  retrieval.
\newblock In {\em Proc. AAAI. Conf. Artif. Intell.}, pages 10786--10793, 2020.

\bibitem{fgsm}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In {\em Proc. Int. Conf. Learn. Representations}, 2015.

\bibitem{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  770--778, 2016.

\bibitem{ensembleweak}
Warren He, James Wei, Xinyun Chen, Nicholas Carlini, and Dawn Song.
\newblock Adversarial example defense: Ensembles of weak defenses are not
  strong.
\newblock In {\em USENIX Workshop on Offensive Technologies}, page~15, 2017.

\bibitem{robustwrn}
Hanxun Huang, Yisen Wang, Sarah~Monazam Erfani, Quanquan Gu, James Bailey, and
  Xingjun Ma.
\newblock Exploring architectural ingredients of adversarially robust deep
  neural networks.
\newblock In {\em Proc. Conf. Neural Inf. Process. Syst.}, 2021.

\bibitem{nes-atk}
Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin.
\newblock Black-box adversarial attacks with limited queries and information.
\newblock In {\em Proc. Int. Conf. Mach. Learn.}, pages 2137--2146, 2018.

\bibitem{adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In {\em Proc. Int. Conf. Learn. Representations}, 2015.

\bibitem{cars196}
Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In {\em Proc. Int. Conf. Comput. Vis. Workshops}, pages 554--561,
  2013.

\bibitem{i-fgsm}
Alexey Kurakin, Ian Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock In {\em Proc. Int. Conf. Learn. Representations Workshops}, 2017.

\bibitem{universalret}
Jie Li, Rongrong Ji, Hong Liu, Xiaopeng Hong, Yue Gao, and Qi Tian.
\newblock Universal perturbation attack against image retrieval.
\newblock In {\em Proc. Int. Conf. Comput. Vis.}, pages 4899--4908, 2019.

\bibitem{qair}
Xiaodan Li, Jinfeng Li, Yuefeng Chen, Shaokai Ye, Yuan He, Shuhui Wang, Hang
  Su, and Hui Xue.
\newblock Qair: Practical query-efficient black-box attacks for image
  retrieval.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, 2021.

\bibitem{onmanifold}
Wei-An Lin, Chun~Pong Lau, Alexander Levine, Rama Chellappa, and Soheil Feizi.
\newblock Dual manifold adversarial robustness: Defense against lp and non-lp
  adversarial attacks.
\newblock {\em arXiv preprint arXiv:2009.02470}, 2020.

\bibitem{self-ensemble}
Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh.
\newblock Towards robust neural networks via random self-ensemble.
\newblock In {\em Proc. Eur. Conf. Comput. Vis.}, pages 369--385, 2018.

\bibitem{madry}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em Proc. Int. Conf. Learn. Representations}, 2018.

\bibitem{dmlreality}
Kevin Musgrave, Serge Belongie, and Ser-Nam Lim.
\newblock A metric learning reality check.
\newblock In {\em Proc. Eur. Conf. Comput. Vis.}, pages 681--699, 2020.

\bibitem{sop}
Hyun Oh~Song, Yu Xiang, Stefanie Jegelka, and Silvio Savarese.
\newblock Deep metric learning via lifted structured feature embedding.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  4004--4012, 2016.

\bibitem{bagoftricks}
Tianyu Pang, Xiao Yang, Yinpeng Dong, Hang Su, and Jun Zhu.
\newblock Bag of tricks for adversarial training.
\newblock In {\em Proc. Int. Conf. Learn. Representations}, 2021.

\bibitem{distill2}
Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In {\em Proc. IEEE Symposium on Security and Privacy}, pages
  582--597, 2016.

\bibitem{deflecting}
Aaditya Prakash, Nick Moran, Solomon Garber, Antonella DiLillo, and James
  Storer.
\newblock Deflecting adversarial attacks with pixel deflection.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  8571--8580, 2018.

\bibitem{overfitting}
Leslie Rice, Eric Wong, and Zico Kolter.
\newblock Overfitting in adversarially robust deep learning.
\newblock In {\em Proc. Int. Conf. Mach. Learn.}, pages 8093--8104, 2020.

\bibitem{revisiting}
Karsten Roth, Timo Milbich, Samarth Sinha, Prateek Gupta, Bjorn Ommer, and
  Joseph~Paul Cohen.
\newblock Revisiting training strategies and generalization performance in deep
  metric learning.
\newblock In {\em Proc. Int. Conf. Mach. Learn.}, pages 8242--8252, 2020.

\bibitem{facenet}
Florian Schroff, Dmitry Kalenichenko, and James Philbin.
\newblock Facenet: A unified embedding for face recognition and clustering.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  815--823, 2015.

\bibitem{freeat}
Ali Shafahi, Mahyar Najibi, Mohammad~Amin Ghiasi, Zheng Xu, John Dickerson,
  Christoph Studer, Larry~S Davis, Gavin Taylor, and Tom Goldstein.
\newblock Adversarial training for free!
\newblock In {\em Proc. Conf. Neural Inf. Process. Syst.}, 2019.

\bibitem{smoothat}
Chawin Sitawarin, Supriyo Chakraborty, and David Wagner.
\newblock Sat: Improving adversarial training via curriculum-based loss
  smoothing.
\newblock In {\em Proc. of the 14th ACM Workshop on Artificial Intelligence and
  Security}, page 25–36, 2021.

\bibitem{l-bfgs}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em Proc. Int. Conf. Learn. Representations}, 2014.

\bibitem{flowertower}
Giorgos Tolias, Filip Radenovic, and Ondrej Chum.
\newblock Targeted mismatch adversarial attack: Query with a flower to retrieve
  the tower.
\newblock In {\em Proc. Int. Conf. Comput. Vis.}, pages 5037--5046, 2019.

\bibitem{adaptive}
Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry.
\newblock On adaptive attacks to adversarial example defenses.
\newblock In {\em Proc. Conf. Neural Inf. Process. Syst.}, pages 1633--1645,
  2020.

\bibitem{odds}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock In {\em Proc. Int. Conf. Learn. Representations}, 2019.

\bibitem{spsa-atk}
Jonathan Uesato, Brendan O’donoghue, Pushmeet Kohli, and Aaron Oord.
\newblock Adversarial risk and the dangers of evaluating against weak attacks.
\newblock In {\em Proc. Int. Conf. Mach. Learn.}, pages 5025--5034, 2018.

\bibitem{learn-to-misrank}
Hongjun Wang, Guangrun Wang, Ya Li, Dongyu Zhang, and Liang Lin.
\newblock Transferable, controllable, and inconspicuous adversarial attacks on
  person re-identification with deep mis-ranking.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  342--351, 2020.

\bibitem{imagesim2}
Jiang Wang, Yang Song, Thomas Leung, Chuck Rosenberg, Jingbin Wang, James
  Philbin, Bo Chen, and Ying Wu.
\newblock Learning fine-grained image similarity with deep ranking.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  1386--1393, 2014.

\bibitem{bilateral}
Jianyu Wang and Haichao Zhang.
\newblock Bilateral adversarial training: Towards fast training of more robust
  models against adversarial attacks.
\newblock In {\em Proc. Int. Conf. Comput. Vis.}, pages 6629--6638, 2019.

\bibitem{advpattern}
Zhibo Wang, Siyan Zheng, Mengkai Song, Qian Wang, Alireza Rahimpour, and
  Hairong Qi.
\newblock Advpattern: Physical-world attacks on deep person re-identification
  via adversarially transformable patterns.
\newblock In {\em Proc. Int. Conf. Comput. Vis.}, pages 8341--8350, 2019.

\bibitem{cub200}
P. Welinder, S. Branson, T. Mita, C. Wah, F. Schroff, S. Belongie, and P.
  Perona.
\newblock Caltech-ucsd birds 200.
\newblock Technical Report CNS-TR-2010-001, California Institute of Technology,
  2010.

\bibitem{fastat}
Eric Wong, Leslie Rice, and J.~Zico Kolter.
\newblock Fast is better than free: Revisiting adversarial training.
\newblock In {\em Proc. Int. Conf. Learn. Representations}, 2020.

\bibitem{distance}
Chao-Yuan Wu, R. Manmatha, Alexander~J. Smola, and Philipp Krahenbuhl.
\newblock Sampling matters in deep embedding learning.
\newblock In {\em Proc. Int. Conf. Comput. Vis.}, pages 2840--2848, 2017.

\bibitem{weightperturb}
Dongxian Wu, Shu-Tao Xia, and Yisen Wang.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In {\em Proc. Conf. Neural Inf. Process. Syst.}, 2020.

\bibitem{awp}
Dongxian Wu, Shu-Tao Xia, and Yisen Wang.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In {\em Proc. Conf. Neural Inf. Process. Syst.}, 2020.

\bibitem{di-fgsm}
Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou Ren, and
  Alan~L Yuille.
\newblock Improving transferability of adversarial examples with input
  diversity.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  2730--2739, 2019.

\bibitem{lafeat}
Yunrui Yu, Xitong Gao, and Cheng-Zhong Xu.
\newblock Lafeat: Piercing through adversarial defenses with latent features.
\newblock In {\em Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, pages
  5735--5745, 2021.

\bibitem{yopo}
Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, and Bin Dong.
\newblock You only propagate once: Accelerating adversarial training via
  maximal principle.
\newblock In {\em Proc. Conf. Neural Inf. Process. Syst.}, pages 227--238,
  2019.

\bibitem{featurescatter}
Haichao Zhang and Jianyu Wang.
\newblock Defense against adversarial attacks using feature scattering-based
  adversarial training.
\newblock In {\em Proc. Conf. Neural Inf. Process. Syst.}, 2019.

\bibitem{trades}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El~Ghaoui, and
  Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In {\em Proc. Int. Conf. Mach. Learn.}, pages 7472--7482, 2019.

\bibitem{geometry}
Jingfeng Zhang, Jianing Zhu, Gang Niu, Bo Han, Masashi Sugiyama, and Mohan
  Kankanhalli.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock In {\em Proc. Int. Conf. Learn. Representations}, 2021.

\bibitem{advtrain-triplet}
Yaoyao Zhong and Weihong Deng.
\newblock Adversarial learning with margin-based triplet embedding
  regularization.
\newblock In {\em Proc. Int. Conf. Comput. Vis.}, pages 6549--6558, 2019.

\bibitem{ladderloss}
Mo Zhou, Zhenxing Niu, Le Wang, Zhanning Gao, Qilin Zhang, and Gang Hua.
\newblock Ladder loss for coherent visual-semantic embedding.
\newblock In {\em Proc. AAAI. Conf. Artif. Intell.}, pages 13050--13057, 2020.

\bibitem{advrank}
Mo Zhou, Zhenxing Niu, Le Wang, Qilin Zhang, and Gang Hua.
\newblock Adversarial ranking attack and defense.
\newblock In {\em Proc. Eur. Conf. Comput. Vis.}, pages 781--799, 2020.

\bibitem{advorder}
Mo Zhou, Le Wang, Zhenxing Niu, Qilin Zhang, Yinghui Xu, Nanning Zheng, and
  Gang Hua.
\newblock Practical relative order attack in deep ranking.
\newblock In {\em Proc. Int. Conf. Comput. Vis.}, 2021.

\bibitem{robrank}
Mo Zhou, Le Wang, Zhenxing Niu, Qilin Zhang, Nanning Zheng, and Gang Hua.
\newblock Adversarial attack and defense in deep ranking.
\newblock In {\em arXiv preprint 2106.03614}, 2021.

\end{thebibliography}
